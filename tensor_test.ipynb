{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "### https://blog.csdn.net/lemonbit/article/details/121586067"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "45a09e19ec6e2b68"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6]])\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "2\n",
      "torch.Size([2, 3])\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "t = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
    "print(t)\n",
    "print(\"*-\"*12)\n",
    "print(t.ndim) #查看维度\n",
    "print(t.shape) #查看形状\n",
    "print(t.numel()) #查看元素个数"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-08T13:20:18.415542100Z",
     "start_time": "2024-06-08T13:20:18.355399900Z"
    }
   },
   "id": "initial_id",
   "execution_count": 126
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 变形"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c0762fdc5755c378"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3, 4, 5, 6])\n",
      "tensor([[[1, 2],\n",
      "         [3, 4],\n",
      "         [5, 6]]])\n",
      "tensor([[[1],\n",
      "         [2],\n",
      "         [3]],\n",
      "\n",
      "        [[4],\n",
      "         [5],\n",
      "         [6]]])\n"
     ]
    }
   ],
   "source": [
    "print(t.flatten())\n",
    "print(t.reshape(1, 3, 2))\n",
    "print(t.reshape((2, 3, 1)))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-08T13:20:18.452916600Z",
     "start_time": "2024-06-08T13:20:18.418942500Z"
    }
   },
   "id": "5fdef0c7cb8f3314",
   "execution_count": 127
  },
  {
   "cell_type": "markdown",
   "source": [
    "###  压缩与维度扩充"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7e056a46b46f3774"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 1])\n",
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6]])\n",
      "torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "t = t.reshape((2, 3, 1))\n",
    "print(t.shape)\n",
    "t_s = t.squeeze(2) # 对第三个维度进行压缩, 若不填参数则压缩所有维度为1的维度\n",
    "print(t_s)\n",
    "print(t_s.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-08T13:20:18.497858200Z",
     "start_time": "2024-06-08T13:20:18.457506500Z"
    }
   },
   "id": "333d54edd1f5fd9d",
   "execution_count": 128
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1, 2, 3]],\n",
      "\n",
      "        [[4, 5, 6]]])\n",
      "torch.Size([2, 1, 3])\n"
     ]
    }
   ],
   "source": [
    "t_s = t_s.unsqueeze(1)     # unsqueeze的作用是解压张量，给指定位置加上维数为一的维度，不能不填维度。\n",
    "print(t_s)\n",
    "print(t_s.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-08T13:20:18.542928400Z",
     "start_time": "2024-06-08T13:20:18.501303Z"
    }
   },
   "id": "3643efa4a793c1e2",
   "execution_count": 129
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 二维张量索引"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b55efbc4a7758045"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1,  2,  3,  4],\n",
      "        [ 5,  6,  7,  8],\n",
      "        [ 9, 10, 11, 12],\n",
      "        [13, 14, 15, 16]])\n",
      "tensor(2)\n",
      "tensor(2)\n",
      "tensor([[ 1,  3],\n",
      "        [ 9, 11]])\n",
      "tensor([[1, 2, 3, 4]])\n"
     ]
    }
   ],
   "source": [
    "t2 = torch.arange(1, 17).reshape(4, 4)\n",
    "print(t2)\n",
    "print(t2[0, 1])\n",
    "print(t2[0][1])  # t2[0,1]也可用t2[0][1]的表示。\n",
    "print(t2[::2, ::2])\n",
    "print(t2[::2][::2]) # 但是t2[::2, ::2]与t2[::2][ ::2]的索引结果就不同：（因为这种写法要 左结合, 相当于一直在取行，最后只能取出第一行）"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-08T13:20:18.606055400Z",
     "start_time": "2024-06-08T13:20:18.547799700Z"
    }
   },
   "id": "61695499b3a4e0f6",
   "execution_count": 130
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 三维张量索引"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a058964840eb0307"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 1,  2,  3],\n",
      "         [ 4,  5,  6],\n",
      "         [ 7,  8,  9]],\n",
      "\n",
      "        [[10, 11, 12],\n",
      "         [13, 14, 15],\n",
      "         [16, 17, 18]],\n",
      "\n",
      "        [[19, 20, 21],\n",
      "         [22, 23, 24],\n",
      "         [25, 26, 27]]])\n",
      "tensor(14)\n",
      "tensor([[10, 12],\n",
      "        [16, 18]])\n"
     ]
    }
   ],
   "source": [
    "t3 = torch.arange(1, 28).reshape(3, 3, 3)\n",
    "print(t3)\n",
    "print(t3[1, 1, 1])  # 索引第二个矩阵中的第二行、第二个元素\n",
    "print(t3[1, ::2, ::2]) # 索引第二个矩阵，行和列都是每隔两个取一个"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-08T13:20:18.631434300Z",
     "start_time": "2024-06-08T13:20:18.610616900Z"
    }
   },
   "id": "c8bda53de947ebaa",
   "execution_count": 131
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 张量的分割"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7312bfb825a816df"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0,  1,  2],\n",
      "        [ 3,  4,  5],\n",
      "        [ 6,  7,  8],\n",
      "        [ 9, 10, 11]])\n"
     ]
    }
   ],
   "source": [
    "t2 = torch.arange(12).reshape(4, 3)  # 创建一个4×3的矩阵\n",
    "print(t2)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-08T13:20:18.714760600Z",
     "start_time": "2024-06-08T13:20:18.636181500Z"
    }
   },
   "id": "29b249453048ac8",
   "execution_count": 132
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### 返回的张量tc的一个视图，不是新成了一个对象"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "52cd4c066ee0d824"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[0, 1, 2],\n",
      "        [3, 4, 5]]), tensor([[ 6,  7,  8],\n",
      "        [ 9, 10, 11]]))\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "tc = torch.chunk(t2, chunks = 3, dim = 0) # 在第0维度上分割成3块，因为无法等分，所以可能小于3块。\n",
    "print(tc)\n",
    "print(len(tc)) # 若原张量不能均分时，chunk不会报错，会返回次一级均分结果。"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-08T13:20:18.715865600Z",
     "start_time": "2024-06-08T13:20:18.656961900Z"
    }
   },
   "id": "54eefd300fca9a76",
   "execution_count": 133
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### 与chunk函数不同的是，split第二个参数可以输入一个序列，表示按照序列数值分，序列各数值的和必须等于对应维度下形状分量的取值"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "85987c784b4924d0"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[0, 1, 2]]), tensor([[3, 4, 5],\n",
      "        [6, 7, 8]]), tensor([[ 9, 10, 11]]))\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "tc2 = torch.split(t2, [1,2,1], dim = 0) \n",
    "print(tc2)\n",
    "print(len(tc2))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-08T13:20:18.738630900Z",
     "start_time": "2024-06-08T13:20:18.720457800Z"
    }
   },
   "id": "6bd8075d8a800aa2",
   "execution_count": 134
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 张量的拼接cat"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c963c468d93852dc"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "torch.Size([4, 3])\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "tensor([[0., 0., 0., 1., 1., 1.],\n",
      "        [0., 0., 0., 1., 1., 1.]])\n",
      "torch.Size([2, 6])\n"
     ]
    }
   ],
   "source": [
    "a = torch.zeros(2, 3)\n",
    "print(a)\n",
    "b = torch.ones(2, 3)\n",
    "print(b)\n",
    "tcat1 = torch.cat([a, b], dim = 0)\n",
    "tcat2 = torch.cat([a, b], dim = 1)\n",
    "print(\"*-\"*12)\n",
    "print(tcat1) # 在第0维度上拼接，其他维度不变。0维上拼接后，形状变为(4, 3)\n",
    "print(tcat1.shape)\n",
    "print(\"*-\"*12)\n",
    "print(tcat2) # 在第1维度上拼接，其他维度不变。1维上拼接后，形状变为(2, 6)\n",
    "print(tcat2.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-08T13:20:18.821468200Z",
     "start_time": "2024-06-08T13:20:18.744527200Z"
    }
   },
   "id": "1156e4f3888e7622",
   "execution_count": 135
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0., 0., 0.],\n",
      "         [0., 0., 0.]],\n",
      "\n",
      "        [[1., 1., 1.],\n",
      "         [1., 1., 1.]]])\n",
      "torch.Size([2, 2, 3])\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "tensor([[[0., 1.],\n",
      "         [0., 1.],\n",
      "         [0., 1.]],\n",
      "\n",
      "        [[0., 1.],\n",
      "         [0., 1.],\n",
      "         [0., 1.]]])\n",
      "torch.Size([2, 3, 2])\n"
     ]
    }
   ],
   "source": [
    "tstack = torch.stack([a, b], dim = 0)\n",
    "print(tstack) # 和拼接不同，堆叠不将元素拆分重装，而是将参与堆叠的对象分装到一个更高维度的张量里。\n",
    "print(tstack.shape)\n",
    "print(\"*-\"*12)\n",
    "tstack2 = torch.stack([a, b], dim = 2)\n",
    "print(tstack2)\n",
    "print(tstack2.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-08T13:20:18.822589600Z",
     "start_time": "2024-06-08T13:20:18.762126500Z"
    }
   },
   "id": "fa976fb1bd2506fc",
   "execution_count": 136
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "7644daf818942eb"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
